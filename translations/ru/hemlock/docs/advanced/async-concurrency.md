# Асинхронность и конкурентность в Hemlock

Hemlock предоставляет **структурированную конкурентность** с синтаксисом async/await, порождением задач и каналами для коммуникации. Реализация использует POSIX-потоки (pthreads) для **настоящего многопоточного параллелизма**.

## Содержание

- [Обзор](#обзор)
- [Модель потоков](#модель-потоков)
- [Асинхронные функции](#асинхронные-функции)
- [Порождение задач](#порождение-задач)
- [Каналы](#каналы)
- [Распространение исключений](#распространение-исключений)
- [Детали реализации](#детали-реализации)
- [Лучшие практики](#лучшие-практики)
- [Характеристики производительности](#характеристики-производительности)
- [Текущие ограничения](#текущие-ограничения)

## Обзор

**Что это означает:**
- **Настоящие потоки ОС** - Каждая порождённая задача выполняется в отдельном pthread (POSIX-потоке)
- **Истинный параллелизм** - Задачи выполняются одновременно на нескольких ядрах CPU
- **Планирование ядром** - Планировщик ОС распределяет задачи по доступным ядрам
- **Потокобезопасные каналы** - Используются мьютексы pthread и условные переменные для синхронизации

**Чем это НЕ является:**
- **НЕ зелёные потоки** - Не кооперативная многозадачность в пользовательском пространстве
- **НЕ корутины async/await** - Не однопоточный цикл событий как в JavaScript/Python asyncio
- **НЕ эмулированная конкурентность** - Не симулированный параллелизм

Это **та же модель потоков, что в C, C++ и Rust** при использовании потоков ОС. Вы получаете реальное параллельное выполнение на нескольких ядрах.

## Модель потоков

### Соотношение 1:1

Hemlock использует **модель потоков 1:1**, где:
- Каждая порождённая задача создаёт выделенный поток ОС через `pthread_create()`
- Ядро ОС планирует потоки по доступным ядрам CPU
- Вытесняющая многозадачность - ОС может прерывать и переключать потоки
- **Нет GIL** - В отличие от Python, нет глобальной блокировки интерпретатора, ограничивающей параллелизм

### Механизмы синхронизации

- **Мьютексы** - Каналы используют `pthread_mutex_t` для потокобезопасного доступа
- **Условные переменные** - Блокирующие send/recv используют `pthread_cond_t` для эффективного ожидания
- **Неблокирующие операции** - Переходы состояний задач атомарны

## Асинхронные функции

Функции могут быть объявлены как `async`, чтобы указать, что они предназначены для конкурентного выполнения:

```hemlock
async fn compute(n: i32): i32 {
    let sum = 0;
    let i = 0;
    while (i < n) {
        sum = sum + i;
        i = i + 1;
    }
    return sum;
}
```

### Ключевые моменты

- `async fn` объявляет асинхронную функцию
- Асинхронные функции могут быть порождены как конкурентные задачи с помощью `spawn()`
- Асинхронные функции также можно вызывать напрямую (выполняются синхронно в текущем потоке)
- При порождении каждая задача выполняется в **собственном потоке ОС** (не корутина!)
- Ключевое слово `await` зарезервировано для будущего использования

### Пример: Прямой вызов vs Порождение

```hemlock
async fn factorial(n: i32): i32 {
    if (n <= 1) { return 1; }
    return n * factorial(n - 1);
}

// Прямой вызов - выполняется синхронно
let result1 = factorial(5);  // 120

// Порождённая задача - выполняется в отдельном потоке
let task = spawn(factorial, 5);
let result2 = join(task);  // 120
```

## Порождение задач

Используйте `spawn()` для запуска асинхронных функций **параллельно в отдельных потоках ОС**:

```hemlock
async fn factorial(n: i32): i32 {
    if (n <= 1) { return 1; }
    return n * factorial(n - 1);
}

// Порождение нескольких задач - они выполняются ПАРАЛЛЕЛЬНО на разных ядрах CPU!
let t1 = spawn(factorial, 5);  // Поток 1
let t2 = spawn(factorial, 6);  // Поток 2
let t3 = spawn(factorial, 7);  // Поток 3

// Все три вычисляются одновременно прямо сейчас!

// Ожидание результатов
let f5 = join(t1);  // 120
let f6 = join(t2);  // 720
let f7 = join(t3);  // 5040
```

### Встроенные функции

#### spawn(async_fn, arg1, arg2, ...)

Создаёт новую задачу в новом pthread, возвращает дескриптор задачи.

**Параметры:**
- `async_fn` - Асинхронная функция для выполнения
- `arg1, arg2, ...` - Аргументы для передачи функции

**Возвращает:** Дескриптор задачи (непрозрачное значение для использования с `join()` или `detach()`)

**Пример:**
```hemlock
async fn process(data: string, count: i32): i32 {
    // ... логика обработки
    return count * 2;
}

let task = spawn(process, "test", 42);
```

#### join(task)

Ожидание завершения задачи (блокируется до завершения потока), возвращает результат.

**Параметры:**
- `task` - Дескриптор задачи, возвращённый из `spawn()`

**Возвращает:** Значение, возвращённое асинхронной функцией

**Пример:**
```hemlock
let task = spawn(compute, 1000);
let result = join(task);  // Блокируется до завершения compute()
print(result);
```

**Важно:** Каждую задачу можно присоединить только один раз. Последующие присоединения вызовут ошибку.

#### detach(task)

Выполнение по принципу "запустил и забыл" (поток работает независимо, join невозможен).

**Параметры:**
- `task` - Дескриптор задачи, возвращённый из `spawn()`

**Возвращает:** `null`

**Пример:**
```hemlock
async fn background_work() {
    // Долго выполняющаяся фоновая задача
    // ...
}

let task = spawn(background_work);
detach(task);  // Задача работает независимо, присоединение невозможно
```

**Важно:** Отсоединённые задачи нельзя присоединить. И pthread, и структура Task автоматически очищаются при завершении задачи.

## Каналы

Каналы обеспечивают потокобезопасную коммуникацию между задачами с использованием ограниченного буфера с блокирующей семантикой.

### Создание каналов

```hemlock
let ch = channel(10);  // Создание канала с размером буфера 10
```

**Параметры:**
- `capacity` (i32) - Максимальное количество значений, которое может содержать канал

**Возвращает:** Объект канала

### Методы каналов

#### send(value)

Отправка значения в канал (блокируется, если канал полон).

```hemlock
async fn producer(ch, count: i32) {
    let i = 0;
    while (i < count) {
        ch.send(i * 10);
        i = i + 1;
    }
    ch.close();
    return null;
}

let ch = channel(10);
let task = spawn(producer, ch, 5);
```

**Поведение:**
- Если в канале есть место, значение добавляется немедленно
- Если канал полон, отправитель блокируется до появления места
- Если канал закрыт, выбрасывается исключение

#### recv()

Получение значения из канала (блокируется, если канал пуст).

```hemlock
async fn consumer(ch, count: i32): i32 {
    let sum = 0;
    let i = 0;
    while (i < count) {
        let val = ch.recv();
        sum = sum + val;
        i = i + 1;
    }
    return sum;
}

let ch = channel(10);
let task = spawn(consumer, ch, 5);
```

**Поведение:**
- Если в канале есть значения, возвращает следующее значение немедленно
- Если канал пуст, получатель блокируется до появления значения
- Если канал закрыт и пуст, возвращает `null`

#### close()

Закрытие канала (recv на закрытом канале возвращает null).

```hemlock
ch.close();
```

**Поведение:**
- Предотвращает дальнейшие операции `send()` (вызовут исключение)
- Позволяет завершить ожидающие операции `recv()`
- После опустошения `recv()` возвращает `null`

### Мультиплексирование с select()

Функция `select()` позволяет ожидать на нескольких каналах одновременно, возвращаясь, когда в любом канале появятся данные.

**Сигнатура:**
```hemlock
select(channels: array, timeout_ms?: i32): object | null
```

**Параметры:**
- `channels` - Массив значений каналов
- `timeout_ms` (опционально) - Таймаут в миллисекундах (-1 или опустить для бесконечного ожидания)

**Возвращает:**
- `{ channel, value }` - Объект с каналом, в котором были данные, и полученным значением
- `null` - При таймауте (если таймаут был указан)

**Пример:**
```hemlock
let ch1 = channel(1);
let ch2 = channel(1);

// Задачи-производители
spawn(fn() {
    sleep(100);
    ch1.send("из канала 1");
});

spawn(fn() {
    sleep(50);
    ch2.send("из канала 2");
});

// Ожидание первого результата (ch2 должен быть быстрее)
let result = select([ch1, ch2]);
print(result.value);  // "из канала 2"

// Ожидание второго результата
let result2 = select([ch1, ch2]);
print(result2.value);  // "из канала 1"
```

**С таймаутом:**
```hemlock
let ch = channel(1);

// Нет отправителя, будет таймаут
let result = select([ch], 100);  // таймаут 100мс
if (result == null) {
    print("Таймаут!");
}
```

**Случаи использования:**
- Ожидание самого быстрого из нескольких источников данных
- Реализация таймаутов для операций с каналами
- Паттерны цикла событий с несколькими источниками событий
- Fan-in: объединение нескольких каналов в один

**Паттерн fan-in:**
```hemlock
fn fan_in(channels: array, output: channel) {
    while (true) {
        let result = select(channels);
        if (result == null) {
            break;  // Все каналы закрыты
        }
        output.send(result.value);
    }
    output.close();
}
```

### Полный пример производитель-потребитель

```hemlock
async fn producer(ch, count: i32) {
    let i = 0;
    while (i < count) {
        ch.send(i * 10);
        i = i + 1;
    }
    ch.close();
    return null;
}

async fn consumer(ch, count: i32): i32 {
    let sum = 0;
    let i = 0;
    while (i < count) {
        let val = ch.recv();
        sum = sum + val;
        i = i + 1;
    }
    return sum;
}

// Создание канала с размером буфера
let ch = channel(10);

// Порождение производителя и потребителя
let p = spawn(producer, ch, 5);
let c = spawn(consumer, ch, 5);

// Ожидание завершения
join(p);
let total = join(c);  // 100 (0+10+20+30+40)
print(total);
```

### Несколько производителей, несколько потребителей

Каналы могут безопасно разделяться между несколькими производителями и потребителями:

```hemlock
async fn producer(id: i32, ch, count: i32) {
    let i = 0;
    while (i < count) {
        ch.send(id * 100 + i);
        i = i + 1;
    }
}

async fn consumer(id: i32, ch, count: i32): i32 {
    let sum = 0;
    let i = 0;
    while (i < count) {
        let val = ch.recv();
        sum = sum + val;
        i = i + 1;
    }
    return sum;
}

let ch = channel(20);

// Несколько производителей
let p1 = spawn(producer, 1, ch, 5);
let p2 = spawn(producer, 2, ch, 5);

// Несколько потребителей
let c1 = spawn(consumer, 1, ch, 5);
let c2 = spawn(consumer, 2, ch, 5);

// Ожидание всех
join(p1);
join(p2);
let sum1 = join(c1);
let sum2 = join(c2);
print(sum1 + sum2);
```

## Распространение исключений

Исключения, выброшенные в порождённых задачах, распространяются при присоединении:

```hemlock
async fn risky_operation(should_fail: i32): i32 {
    if (should_fail == 1) {
        throw "Задача завершилась с ошибкой!";
    }
    return 42;
}

let t = spawn(risky_operation, 1);
try {
    let result = join(t);
} catch (e) {
    print("Перехвачено: " + e);  // "Перехвачено: Задача завершилась с ошибкой!"
}
```

### Паттерны обработки исключений

**Паттерн 1: Обработка в задаче**
```hemlock
async fn safe_task() {
    try {
        // рискованная операция
    } catch (e) {
        print("Ошибка в задаче: " + e);
        return null;
    }
}

let task = spawn(safe_task);
join(task);  // Исключение не распространяется
```

**Паттерн 2: Распространение вызывающему**
```hemlock
async fn task_that_throws() {
    throw "ошибка";
}

let task = spawn(task_that_throws);
try {
    join(task);
} catch (e) {
    print("Перехвачено из задачи: " + e);
}
```

**Паттерн 3: Отсоединённые задачи с исключениями**
```hemlock
async fn detached_task() {
    try {
        // работа
    } catch (e) {
        // Необходимо обрабатывать внутренне - невозможно распространить
        print("Ошибка: " + e);
    }
}

let task = spawn(detached_task);
detach(task);  // Невозможно перехватить исключения из отсоединённых задач
```

## Детали реализации

### Архитектура потоков

- **Соотношение 1:1** - Каждая порождённая задача создаёт выделенный поток ОС через `pthread_create()`
- **Планирование ядром** - Ядро ОС планирует потоки по доступным ядрам CPU
- **Вытесняющая многозадачность** - ОС может прерывать и переключать потоки
- **Нет GIL** - В отличие от Python, нет глобальной блокировки интерпретатора, ограничивающей параллелизм

### Реализация каналов

Каналы используют кольцевой буфер с синхронизацией pthread:

```
Структура канала:
- buffer[] - Массив значений фиксированного размера
- capacity - Максимальное количество элементов
- size - Текущее количество элементов
- head - Позиция чтения
- tail - Позиция записи
- mutex - pthread_mutex_t для потокобезопасного доступа
- not_empty - pthread_cond_t для блокирующего recv
- not_full - pthread_cond_t для блокирующего send
- closed - Булевый флаг
- refcount - Счётчик ссылок для очистки
```

**Блокирующее поведение:**
- `send()` на полном канале: ожидает на условной переменной `not_full`
- `recv()` на пустом канале: ожидает на условной переменной `not_empty`
- Оба сигнализируются, когда это уместно, противоположной операцией

### Память и очистка

- **Присоединённые задачи:** Автоматически очищаются после возврата `join()`
- **Отсоединённые задачи:** Автоматически очищаются при завершении задачи
- **Каналы:** Подсчёт ссылок и освобождение при отсутствии использования

## Лучшие практики

### 1. Всегда закрывайте каналы

```hemlock
async fn producer(ch) {
    // ... отправка значений
    ch.close();  // Важно: сигнализировать, что больше значений не будет
}
```

### 2. Используйте структурированную конкурентность

Порождайте задачи и присоединяйте их в той же области видимости:

```hemlock
fn process_data(data) {
    // Порождение задач
    let t1 = spawn(worker, data);
    let t2 = spawn(worker, data);

    // Всегда присоединяйте перед возвратом
    let r1 = join(t1);
    let r2 = join(t2);

    return r1 + r2;
}
```

### 3. Обрабатывайте исключения надлежащим образом

```hemlock
async fn task() {
    try {
        // рискованная операция
    } catch (e) {
        // Логирование ошибки
        throw e;  // Повторно выбросить, если вызывающий должен знать
    }
}
```

### 4. Используйте подходящую ёмкость канала

- **Малая ёмкость (1-10):** Для координации/сигнализации
- **Средняя ёмкость (10-100):** Для общего паттерна производитель-потребитель
- **Большая ёмкость (100+):** Для сценариев высокой пропускной способности

```hemlock
let signal_ch = channel(1);      // Координация
let work_ch = channel(50);       // Очередь работ
let buffer_ch = channel(1000);   // Высокая пропускная способность
```

### 5. Отсоединяйте только при необходимости

Предпочитайте `join()` вместо `detach()` для лучшего управления ресурсами:

```hemlock
// Хорошо: Присоединить и получить результат
let task = spawn(work);
let result = join(task);

// Используйте detach только для настоящих "запустил и забыл"
let bg_task = spawn(background_logging);
detach(bg_task);  // Будет работать независимо
```

## Характеристики производительности

### Истинный параллелизм

- **N порождённых задач могут использовать N ядер CPU одновременно**
- Доказанное ускорение - стресс-тесты показывают 8-9x CPU-время vs реальное время (работают несколько ядер)
- Линейное масштабирование с количеством ядер (до числа потоков)

### Накладные расходы на потоки

- Каждая задача имеет ~8KB стека + накладные расходы pthread
- Стоимость создания потока: ~10-20мкс
- Стоимость переключения контекста: ~1-5мкс

### Когда использовать Async

**Хорошие случаи использования:**
- Вычислительно-интенсивные задачи, которые можно распараллелить
- I/O-интенсивные операции (хотя I/O всё ещё блокирующий)
- Конкурентная обработка независимых данных
- Конвейерные архитектуры с каналами

**Не идеально для:**
- Очень коротких задач (доминируют накладные расходы на потоки)
- Задач с интенсивной синхронизацией (накладные расходы на конкуренцию)
- Одноядерных систем (нет преимуществ параллелизма)

### Безопасность блокирующего I/O

Блокирующие операции в одной задаче не блокируют другие:

```hemlock
async fn reader(filename: string) {
    let f = open(filename, "r");  // Блокирует только этот поток
    let content = f.read();       // Блокирует только этот поток
    f.close();
    return content;
}

// Оба читают конкурентно (в разных потоках)
let t1 = spawn(reader, "file1.txt");
let t2 = spawn(reader, "file2.txt");

let c1 = join(t1);
let c2 = join(t2);
```

## Модель потокобезопасности

Hemlock использует модель конкурентности **передачи сообщений**, где задачи коммуницируют через каналы, а не через общее изменяемое состояние.

### Изоляция аргументов

Когда вы порождаете задачу, **аргументы глубоко копируются** для предотвращения гонок данных:

```hemlock
async fn modify_array(arr: array): array {
    arr.push(999);    // Модифицирует КОПИЮ, не оригинал
    arr[0] = -1;
    return arr;
}

let original = [1, 2, 3];
let task = spawn(modify_array, original);
let modified = join(task);

print(original.length);  // 3 - не изменён!
print(modified.length);  // 4 - есть новый элемент
```

**Что глубоко копируется:**
- Массивы (и все элементы рекурсивно)
- Объекты (и все поля рекурсивно)
- Строки
- Буферы

**Что разделяется (ссылка сохраняется):**
- Каналы (механизм коммуникации - намеренно разделяемый)
- Дескрипторы задач (для координации)
- Функции (код неизменяем)
- Файловые дескрипторы (ОС управляет конкурентным доступом)
- Сокетные дескрипторы (ОС управляет конкурентным доступом)

**Что нельзя передавать:**
- Сырые указатели (`ptr`) - используйте вместо этого `buffer`

### Почему передача сообщений?

Это следует философии Hemlock "явное важнее неявного":

```hemlock
// ПЛОХО: Общее изменяемое состояние (вызовет гонки данных)
let counter = { value: 0 };
let t1 = spawn(fn() { counter.value = counter.value + 1; });  // Гонка!
let t2 = spawn(fn() { counter.value = counter.value + 1; });  // Гонка!

// ХОРОШО: Передача сообщений через каналы
async fn increment(ch) {
    let val = ch.recv();
    ch.send(val + 1);
}

let ch = channel(1);
ch.send(0);
let t1 = spawn(increment, ch);
join(t1);
let result = ch.recv();  // 1 - нет состояния гонки
```

### Потокобезопасность подсчёта ссылок

Все операции подсчёта ссылок используют **атомарные операции** для предотвращения ошибок использования после освобождения:
- `string_retain/release` - атомарные
- `array_retain/release` - атомарные
- `object_retain/release` - атомарные
- `buffer_retain/release` - атомарные
- `function_retain/release` - атомарные
- `channel_retain/release` - атомарные
- `task_retain/release` - атомарные

Это обеспечивает безопасное управление памятью даже когда значения разделяются между потоками.

### Доступ к окружению замыкания

Задачи имеют доступ к окружению замыкания для:
- Встроенных функций (`print`, `len`, и т.д.)
- Глобальных определений функций
- Констант и переменных

Окружение замыкания защищено мьютексом для каждого окружения, что делает
конкурентные чтения и записи потокобезопасными:

```hemlock
let x = 10;

async fn read_closure(): i32 {
    return x;  // OK: чтение переменной замыкания (потокобезопасно)
}

async fn modify_closure() {
    x = 20;  // OK: запись переменной замыкания (синхронизировано мьютексом)
}
```

**Примечание:** Хотя конкурентный доступ синхронизирован, изменение общего состояния из
нескольких задач всё ещё может привести к логическим состояниям гонки (недетерминированный
порядок). Для предсказуемого поведения используйте каналы для коммуникации задач или
возвращаемые значения из задач.

Если вам нужно вернуть данные из задачи, используйте возвращаемое значение или каналы.

## Текущие ограничения

### 1. Нет планировщика с кражей работы

Использует 1 поток на задачу, что может быть неэффективно для многих коротких задач.

**Текущее:** 1000 задач = 1000 потоков (большие накладные расходы)

**Планируется:** Пул потоков с кражей работы для лучшей эффективности

### 3. Нет интеграции асинхронного I/O

Файловые/сетевые операции всё ещё блокируют поток:

```hemlock
async fn read_file(path: string) {
    let f = open(path, "r");
    let content = f.read();  // Блокирует поток
    f.close();
    return content;
}
```

**Обходной путь:** Используйте несколько потоков для конкурентных I/O операций

### 4. Фиксированная ёмкость канала

Ёмкость канала устанавливается при создании и не может быть изменена:

```hemlock
let ch = channel(10);
// Невозможно динамически изменить до 20
```

### 5. Размер канала фиксирован

Размер буфера канала нельзя изменить после создания.

## Распространённые паттерны

### Параллельный Map

```hemlock
async fn map_worker(ch_in, ch_out, fn_transform) {
    while (true) {
        let val = ch_in.recv();
        if (val == null) { break; }

        let result = fn_transform(val);
        ch_out.send(result);
    }
    ch_out.close();
}

fn parallel_map(data, fn_transform, workers: i32) {
    let ch_in = channel(100);
    let ch_out = channel(100);

    // Порождение воркеров
    let tasks = [];
    let i = 0;
    while (i < workers) {
        tasks.push(spawn(map_worker, ch_in, ch_out, fn_transform));
        i = i + 1;
    }

    // Отправка данных
    let i = 0;
    while (i < data.length) {
        ch_in.send(data[i]);
        i = i + 1;
    }
    ch_in.close();

    // Сбор результатов
    let results = [];
    let i = 0;
    while (i < data.length) {
        results.push(ch_out.recv());
        i = i + 1;
    }

    // Ожидание воркеров
    let i = 0;
    while (i < tasks.length) {
        join(tasks[i]);
        i = i + 1;
    }

    return results;
}
```

### Конвейерная архитектура

```hemlock
async fn stage1(input_ch, output_ch) {
    while (true) {
        let val = input_ch.recv();
        if (val == null) { break; }
        output_ch.send(val * 2);
    }
    output_ch.close();
}

async fn stage2(input_ch, output_ch) {
    while (true) {
        let val = input_ch.recv();
        if (val == null) { break; }
        output_ch.send(val + 10);
    }
    output_ch.close();
}

// Создание конвейера
let ch1 = channel(10);
let ch2 = channel(10);
let ch3 = channel(10);

let s1 = spawn(stage1, ch1, ch2);
let s2 = spawn(stage2, ch2, ch3);

// Подача входных данных
ch1.send(1);
ch1.send(2);
ch1.send(3);
ch1.close();

// Сбор выходных данных
print(ch3.recv());  // 12 (1 * 2 + 10)
print(ch3.recv());  // 14 (2 * 2 + 10)
print(ch3.recv());  // 16 (3 * 2 + 10)

join(s1);
join(s2);
```

### Fan-Out, Fan-In

```hemlock
async fn worker(id: i32, input_ch, output_ch) {
    while (true) {
        let val = input_ch.recv();
        if (val == null) { break; }

        // Обработка значения
        let result = val * id;
        output_ch.send(result);
    }
}

let input = channel(10);
let output = channel(10);

// Fan-out: Несколько воркеров
let workers = 4;
let tasks = [];
let i = 0;
while (i < workers) {
    tasks.push(spawn(worker, i, input, output));
    i = i + 1;
}

// Отправка работы
let i = 0;
while (i < 10) {
    input.send(i);
    i = i + 1;
}
input.close();

// Fan-in: Сбор всех результатов
let results = [];
let i = 0;
while (i < 10) {
    results.push(output.recv());
    i = i + 1;
}

// Ожидание всех воркеров
let i = 0;
while (i < tasks.length) {
    join(tasks[i]);
    i = i + 1;
}
```

## Итог

Модель асинхронности/конкурентности Hemlock предоставляет:

- Истинный многопоточный параллелизм с использованием потоков ОС
- Простые, структурированные примитивы конкурентности
- Потокобезопасные каналы для коммуникации
- Распространение исключений между задачами
- Доказанная производительность на многоядерных системах
- **Изоляция аргументов** - глубокое копирование предотвращает гонки данных
- **Атомарный подсчёт ссылок** - безопасное управление памятью между потоками

Это делает Hemlock подходящим для:
- Параллельных вычислений
- Конкурентных I/O операций
- Конвейерных архитектур
- Паттернов производитель-потребитель

Избегая сложности:
- Ручного управления потоками
- Низкоуровневых примитивов синхронизации
- Подверженных взаимоблокировкам дизайнов на основе блокировок
- Ошибок общего изменяемого состояния
